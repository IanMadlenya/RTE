{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from build_model import build_model\n",
    "\n",
    "data_x = pd.read_csv('./data/weather/v3/2013/merged/merged_2013_h0.csv', index_col = 'Time')\n",
    "data_x.columns\n",
    "\n",
    "x = data_x[['temperature-460', 'cloudiness-460',\n",
    "            'temperature-481', 'cloudiness-481',\n",
    "            'temperature-645', 'cloudiness-645',]]\n",
    "\n",
    "data_y = pd.read_csv('./data/energy/v5/2013/Consumption_2013.csv', index_col = 'Time')\n",
    "data = x.copy()\n",
    "data['cons'] = data_y['Auvergne-Rhone-Alpes']\n",
    "\n",
    "\n",
    "data.drop(data.index[0], inplace = True)\n",
    "\n",
    "print(data.isnull().values.any())\n",
    "\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.values\n",
    "x_train = data_train[:, 0:6]\n",
    "y_train = data_train[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.isnull().values.any()\n",
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before\n",
    "x_min = np.min(x_train)\n",
    "print(x_min)\n",
    "\n",
    "x_max = np.max(x_train)\n",
    "print(x_max)\n",
    "\n",
    "x_train = (x_train - np.min(x_train)) / (np.max(x_train) - np.min(x_train))\n",
    "\n",
    "# After \n",
    "x_min = np.min(x_train)\n",
    "print(x_min)\n",
    "\n",
    "x_max = np.max(x_train)\n",
    "print(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''y_train = (y_train - np.min(y_train)) / (np.max(y_train) - np.min(y_train))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = pd.read_csv('./data/weather/v3/2014/merged/merged_2014_h0.csv', index_col = 'Time')\n",
    "data_x.columns\n",
    "\n",
    "x = data_x[['temperature-460', 'cloudiness-460',\n",
    "            'temperature-481', 'cloudiness-481',\n",
    "            'temperature-645', 'cloudiness-645',]]\n",
    "\n",
    "data_y = pd.read_csv('./data/energy/v5/2014/Consumption_2014.csv', index_col = 'Time')\n",
    "data = x.copy()\n",
    "data['cons'] = data_y['Auvergne-Rhone-Alpes']\n",
    "\n",
    "\n",
    "#data.drop(data.index[0], inplace = True)\n",
    "\n",
    "print(data.isnull().values.any())\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "data_test = data.values\n",
    "x_test = data_test[:, 0:6]\n",
    "y_test = data_test[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "def data_to_sequence(data, n_prev = seq_len):  \n",
    "    \n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        docX.append(data[i:i+n_prev, 0:6])\n",
    "        docY.append(data[i+n_prev, 6])\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "\n",
    "    return alsX, alsY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = data_to_sequence(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = data_to_sequence(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(features = 6, seq_len = seq_len, out = 1)\n",
    "model.summary()\n",
    "\n",
    "from keras.callbacks import TensorBoard , ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir ='./logs/', \n",
    "                         histogram_freq = 0, \n",
    "                         write_graph = True)\n",
    "\n",
    "filepath = \"best_model.hdf5\"\n",
    "best_model = ModelCheckpoint(filepath = filepath, \n",
    "                             monitor = 'val_loss', \n",
    "                             verbose = 1, \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = False, \n",
    "                             mode = 'auto', period = 1)\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size = 100,\n",
    "          epochs = 100,\n",
    "          validation_data = [x_test, y_test],\n",
    "          callbacks = [best_model, tbCallBack, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
