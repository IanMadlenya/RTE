{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from build_model import build_model\n",
    "\n",
    "data_x = pd.read_csv('./data/weather/v3/2013/merged/merged_2013_h0.csv', index_col = 'Time')\n",
    "data_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_x[['temperature-460', 'cloudiness-460',\n",
    "            'temperature-481', 'cloudiness-481',\n",
    "            'temperature-645', 'cloudiness-645',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = pd.read_csv('./data/energy/v5/2013/Consumption_2013.csv', index_col = 'Time')\n",
    "data = x.copy()\n",
    "data['cons'] = data_y['Auvergne-Rhone-Alpes']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.index[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.values\n",
    "\n",
    "'''\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "data = scale( data, axis=0, with_mean=True, with_std=False, copy=True )\n",
    "data.head()\n",
    "'''\n",
    "\n",
    "x_data = data[:, 0:6]\n",
    "y_data = data[:, 6]\n",
    "x_data.shape\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 1000\n",
    "def data_to_sequence(data, n_prev = seq_len):  \n",
    "\n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        docX.append(data[i:i+n_prev, 0:6])\n",
    "        docY.append(data[i+n_prev, 6])\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "\n",
    "    return alsX, alsY\n",
    "\n",
    "x_data, y_data = data_to_sequence(data)\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(features = 6, seq_len = seq_len, out = 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard , ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir ='./logs/', \n",
    "                         histogram_freq = 0, \n",
    "                         write_graph = True)\n",
    "\n",
    "filepath = \"best_model.hdf5\"\n",
    "best_model = ModelCheckpoint(filepath = filepath, \n",
    "                             monitor = 'val_loss', \n",
    "                             verbose = 1, \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = False, \n",
    "                             mode = 'auto', period = 1)\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_data,\n",
    "          y_data,\n",
    "          batch_size = 100,\n",
    "          epochs = 800,\n",
    "          validation_split = 0.05,\n",
    "          callbacks = [best_model, tbCallBack, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
